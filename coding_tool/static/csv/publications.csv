pub_id|title|year|venue|authors|institution|keywords
1|What Situational Information Would Help Developers When Using a Graphical Code Recommender?|2016|JSS|Seonah Lee; Sungwon Kang|Korea Advanced Institute of Science and Technology|Empirical Software Engineering;Test Driven Development;Process Quality
2|Links between the personalities, styles and performance in computer programming|2015|JSS|Zahra Karimi;Ahmad Baraani-Dastjerdi;Nasser Ghasem-Aghaee;Stefan Wagner|University of Isfahan;Universität Stuttgart|Programming styles;Personality;Five-factor model
3|Bringing Test-Driven Development to web service choreographies|2015|JSS|Felipe Besson;Paulo Moura;Fabio Kon;Dejan Milojicic|University of São Paulo;Hewlett Packard Laboratories|Automated testing;Test-Driven Development;Web service choreographies
4|Tester interactivity makes a difference in search-based software testing: A controlled experiment|2016|IST|Bogdan Marculescu; Simon Poulding; Robert Feldt; Kai Petersen; Richard Torkar|Blekinge Institute of Technology; Chalmers and the University of Gothenburg|Search-based software testing; Interactive search-based software testing; Controlled experiment
5|Evaluating the productivity of a reference-based programming approach: A controlled experiment|2014|IST|Arnon Sturm; Oded Kramer|Ben-Gurion University of Negev|Search-based software testing; Interactive search-based software testing; Controlled experiment
6|Are team personality and climate related to satisfaction and software quality? Aggregating results from a twice replicated experiment|2015|IST|Silvia T. Acuna; Marta N. Gomez; Jo E. Hannay; Natalia Juristo; Dietmar Pfahl|Universidad Autonoma de Madrid; Universidad CEU San Pablo; Norwegian Defence Research Establishment; Universidad Politecnica de Madrid; University of Tartu|Personality factors; Team climate; Software quality; Satisfaction; Replication; Meta-analysis
7|Towards an Operationalization of Test-driven Development Skills: An Industrial Empirical Study|2015|IST|Davide Fucci; Burak Turhan; Natalia Juristo; Oscar Dieste; Ayse Tosun Misirli; Markku Oivo|Universidad Politecnica de Madrid; Istanbul Technical University|test-driven development; process conformance; software quality; developers' productivity
8|An External Replication on the Effects of Test-driven Development Using a Multi-site Blind Analysis Approach|2016|ESEM|Davide Fucci; Giuseppe Scanniello; Simone Romano; Martin Shepperd; Boyce Sigweni; Fernando Uyaguari; Burak Turhan; Natalia Juristo; Markku Oivo|University of Oulu; University of Basilicata; Brunel University; Universidad Politécnica de Madrid|test-driven development; external experiment replication; blind analysis
9|An Experimental Evaluation of Test Driven Development vs. Test-Last Development with Industry Professionals|2014|EASE|Hussan Munir; Krzysztof Wnuk; Kai Petersen; Misagh Moayyed|Lund University; Blekinge Institute of Technology|Test-Driven Development; TDD; Test-Last Development; TLD; Productivity; internal or external code quality
10|Empirical study on the maintainability of Web applications: Model-driven Engineering vs Code-centric|2014|ESEJ|Y. Martínez; C. Cachero; S. Meliá|Universidad Máximo Gómez Báez de Ciego de Ávila;  Universidad de Alicante|Maintainability; Satisfaction; Quasi-experiment; MDE
11|Labeling source code with information retrievalmethods: an empirical study|2014|ESEJ|Andrea De Lucia; Massimiliano Di Penta; Rocco Oliveto; Annibale Panichella; Sebastiano Panichella|University of Salerno; University of Sannio; University of Molise|Program comprehension; Software artifact labeling; Information retrieval; Empirical studies
12|A family of experiments to assess the effectivenessand efficiency of source code obfuscation techniques|2014|ESEJ|Mariano Ceccato; Massimiliano Di Penta; Paolo Falcarin; Filippo Ricca; Marco Torchiano; Paolo Tonella|Fondazione Bruno Kessler; University of Sannio; University of East London; University of Genova; Politecnico di Torino|Program comprehension; Software artifact labeling; Information retrieval; Empirical studies
13|The impact of imperfect change rules on framework APIevolution identification: an empirical study|2015|ESEJ|Wei Wu; Adrien Serveaux; Yann-Gael Gueheneuc; Giuliano Antoniol|Ecole Polytechnique de Montreal|Software maintenance; Usefulness; Framework API evolution; Change rule
14|Prompter|2016|ESEJ|Luca Ponzanelli; Gabriele Bavota; Massimiliano Di Penta; Rocco Oliveto; Michele Lanza|Universita della Svizzera italiana; Free University of Bozen-Bolzano; University of Sannio; University of Molise|Recommenders; Mining software repositories; Stack overflow; Empirical studies
15|Evaluating Advantages of Test Driven Development: a Controlled Experiment with Professionals|2006|ISESE|Gerardo Canfora; Aniello Cimitile; Felix Garcia; Mario Piattini; Corrado Aaron Visaggio|Research Centre on Software Technology (RCOST); University of Castilla-La-Mancha|Empirical Software Engineering; Test Driven Development; Process Quality
16|An Empirical Comparison Between Pair Development and Software Inspection in Thailand|2006|ISESE|Monvorath Phongpaibul; Barry Boehm|University of Southern California; Thammasat University|Software Process Model; Software Verification; Empirical Study; Software Inspection; Pair Programming; Peer Review
17|The effect of experience on the test-driven development process|2007|ESEM|Matthias M. Muller; Andreas Höfer|Systeme Infrastruktur Support GmbH, EnBW AG; Universitat Karlsruhe|Test-driven development; Process; Quasi-experiment; Experts; Novices
18|A Replicate Empirical Comparison between Pair Development and Software Development with Inspection|2007|ISESE|Monvorath Phongpaibul; Barry Boehm|University of Southern California|Empirical Software Engineering; Test Driven Development; Process Quality
19|Comparing Inspection Methods using Controlled Experiments|2008|ESEM|Andrea De Lucia; Fausto Fasano; Giuseppe Scanniello; Genoveffa Tortora|University of Salerno; University of Basilicata|Code Inspection; Controlled Experiment; Distributed Inspection; Fagan’s Method; Pair Inspection
20|Experimental evaluation of a tool for the verification and transformation of source code in event-driven systems|2009|ESEJ|Gürcan Güles ̧ir; Klaas van den Berg; Lodewijk Bergmans; Mehmet Aks it|University of Twente|Event-driven systems; Source code verification; Source code transformation; Formal experiment
21|Does Aspect-Oriented Programming Increase the Development Speed for Crosscutting Code? An Empirical Study|2009|ESEM|Stefan Hanenberg; Sebastian Kleinschmager; Manuel Josupeit-Walter|University of Duisburg-Essen|nc
22|Preserving Aspects via Automation: a Maintainability Study|2011|ESEM|Aram Hovsepyan; Riccardo Scandariato; Stefan Van Baelen; Wouter Joosen; Serge Demeyer|Katholieke Universiteit Leuven; Universiteit Antwerpen|Experimental study; domain specific modeling; model driven engineering
23|Evaluating Methods and Technologies in Software Engineering with Respect to Developers’ Skill Level|2012|EASE|Gunnar R. Bergersen; Dag I. K. Sjøberg|University of Oslo|programming skill; pretest; experimental control; debugging; performance; replication
24|Plat_Forms 2011: Finding Emergent Properties of Web Application Development Platforms|2012|ESEM|Ulrich Stärk; Lutz Prechelt; Ilija Jolevski|Freie Universität Berlin; University St. Kliment Ohridski|Experiment; Web Development; Platforms; Comparison; Emergent Properties; Languages; Empirical Software Engineering
25|Are Forward Designed or Reverse-Engineered UML Diagrams More Helpful for Code Maintenance?: A Controlled Experiment|2013|EASE|Ana M. Fernández-Sáez; Michel R.V. Chaudron; Marcela Genero; Isabel Ramos|Leiden University; Chalmers University of Technology; University of Gothenburg; University of Castilla-La-Mancha; University of Seville|Software Maintenance; UML Diagrams; Reverse Engineering; Controlled Experiment; Survey
26|A Replicated Experiment on the Effectiveness of Test-first Development|2013|ESEM|Davide Fucci; Burak Turhan|University of Oulu|nc
27|Are Reviews an Alternative to Pair Programming ?|2004|ESEM|Matthias M. Muller|Universitat Karlsruhe|nc
28|Using Students as Experiment Subjects – An Analysis on Graduate and Freshmen Student Data|2003|EASE|Per Runeson|Lund University|nc
29|Comparing Code Reading Techniques Applied to Object-oriented Software Frameworks with regard to Effectiveness and Defect Detection Rate|2004|ISESE|Zeiad Abdelnabi; Giovanni Cantone; Marcus Ciolkowski; Dieter Rombach|University of Rome “Tor Vergata”|nc
30|Effects of Pair Programming at the Development Team Level: An Experiment|2005|ESEM|Jari Vanhanen; Casper Lassenius|Helsinki University of Technology|nc
31|A Controlled Experiment Comparing the Maintainability of Programs Designed with and without Design Patterns - A Replication in a Real Programming Environment|2004|ESEJ|MAREK VOKA ́ Cˇ; WALTER TICHY; DAG I. K. SJØBERG; ERIK ARISHOLM; MAGNE ALDRIN|Simula Research Laboratory; Universitat Karlsruhe; Norwegian Computing Center|Controlled experiment; design patterns; real programming environment; qualitative results
32|Answering software evolution questions: An empirical evaluation|2012|IST|Lile Hattori; Marco D’Ambros; Michele Lanza; Mircea Lungu|University of Lugano; University of Berne|Software evolution; Empirical evaluation; Controlled experiment; Software change history; Mining software repositories
33|More testers – The effect of crowd size and time restriction in software testing|2013|IST|Mika V. Mäntylä; Juha Itkonen|Aalto University; Lund University|Software testing; Group performance Division of labor; Human factors Crowdsourcing; Methods for SQA and V&V
34|Self-assessment of performance in software inspection processes|2004|IST|Zhichao Yina; Alistair Dunsmoreb; James Miller|University of Alberta; University of Strathclyde|Inspection; Defects; Subjective estimation
35|A structured experiment of test-driven development|2003|IST|Boby Georgea; Laurie Williams|Virginia Polytechnic Institute and State University; North Carolina State University|Software engineering; Test driven development; Extreme programming; Agile methodologies
36|Assessing defect detection performance of interacting teams in object-oriented design inspection|2004|IST|Giedre Sabaliauskaitea; Shinji Kusumoto; Katsuro Inoue|Osaka University; Kaunas University of Technology|Software inspection; Inspection meeting; False positives
37|Experimental comparison of the comprehensibility of a Z specification and its implementation in Java|2004|IST|C.F. Snooka; R. Harrison|University of Southampton; University of Reading|Empirical assessment; Formal Specification; Comprehension
38|Exploring the underlying aspects of pair programming: The impact of personality|2008|IST|Kyungsub S. Choi; Fadi P. Deek; Il Im|Manhattan College; New Jersey Institute of Technology; Yonsei University; University Heights|Pair programming; Team programming; Collaborative programming; Myers–Briggs Type Indicator; Personality
39|The effect of task order on the maintainability of object-oriented software|2009|IST|Alf Inge Wang; Erik Arisholm|Norwegian University of Science and Technology; Simula Research Laboratory; University of Oslo|Object-oriented design; Object-oriented programming; Maintainability; Maintenance planning; Software maintenance; Schedule and organizational issues
40|Empirical investigation towards the effectiveness of Test First programming|2009|IST|Liang Huang; Mike Holcombe|University of Sheffield|Agile methods; Empirical software engineering; Software testing; Testing strategies; Software engineering process; Programming paradigms
41|The impacts of function extraction technology on program comprehension: A controlled experiment|2008|IST|Rosann Webb Collins; Alan R. Hevner; Gwendolyn H. Walton; Richard C. Linger|University of South Florida; Florida Southern College; Carnegie-Mellon University|Program comprehension; Behavior understanding; Knowledge workers; Software development; Function extraction
42|The impact of Test-First programming on branch coverage and mutation score indicator of unit tests: An experiment|2010|IST|Lech Madeyski|Wroclaw University of Technology|Empirical study; Test-First programming; Test-driven development; Unit tests
43|A controlled experiment in assessing and estimating software maintenance tasks|2011|IST|Vu Nguyen; Barry Boehm; Phongphan Danphitsanuphan|University of Southern California; King Mongkut’s University of Technology North Bangkok|Software maintenance; Software estimation; Maintenance experiment; COCOMO; Maintenance size
44|Impact of test-driven development on productivity, code and tests: A controlled experiment|2011|IST|Matjaz Pancur; Mojca Ciglaric|University of Ljubljana|Empirical software engineering; Controlled experiment;Test-driven development; Iterative test-last development
45|Human and program factors affecting the maintenance of programs with deployed design patterns|2012|IST|T.H. Ng; Yuen Tak Yu; S.C. Cheung; W.K. Chan|Hong Kong University of Science and Technology; City University of Hong Kong|Design patterns; Empirical study; Human factors; Pattern-deployed software; Program factors; Software maintenance
46|Design of an empirical study for comparing the usability of concurrent programming languages|2013|IST|Sebastian Nanz; Faraz Torshizi; Michela Pedroni; Bertrand Meyer|ETH Zurich; University of Toronto|Empirical study; Concurrency; Programming languages; Usability
47|A preliminary study on the impact of a pair design phase on pair programming and solo programming|2013|IST|Matthias M. Muler|Universitat Karlsruhe|Pair programming; Preliminary study; Post-development test-cases
48|Predicting Maintenance Performance Using Object-Oriented Design Complexity Metrics|2003|TSE|Rajendra K. Bandi; Vijay K. Vaishnavi; Daniel E. Turk|Indian Institute of Management; Georgia State University; Colorado State University|Object-oriented metrics; software maintenance; metrics validation; predicting software maintenance time
49|Computer-Mediated Group Support, Anonymity, and the Software Inspection Process: An Empirical Investigation|2003|TSE|Padmal Vitharana; K. Ramamurthy|Syracuse University; University of Wisconsin|Anonymity; controlled experiment design; group support systems; seeded errors; software inspection; software quality assurance
50|Evaluating the Effect of a Delegated versus Centralized Control Style on the Maintainability of Object-Oriented Software|2004|TSE|Erik Arisholm; Dag I. K. Sjøberg|Simula Research Laboratory|Design principles; responsibility delegation; control styles; object-oriented design; object-oriented programming; software maintainability; controlled experiment
51|On the Effectiveness of the Test-First Approach to Programming|2005|TSE|Hakan Erdogmus; Maurizio Morisio; Marco Torchiano|National Research Council Canada; Politecnico di Torino|General programming techniques; coding tools and techniques; testing and debugging; testing strategies; productivity; Software Quality/SQA; software engineering process; programming paradigms
52|The Structural Complexity of Software: An Experimental Test|2005|TSE|David P. Darcy; Chris F. Kemerer; Sandra A. Slaughter; James E. Tomayko|University of Maryland; University of Pittsburgh; Carnegie-Mellon University|Software complexity; software structure; Wood’s model of task complexity; coupling; cohesion; experiment; software maintenance; software metrics; cognition; procedural programming; object-oriented programming
53|Evaluating Pair Programming with Respect to System Complexity and Programmer Expertise|2007|TSE|Erik Arisholm; Hans Gallis; Tore Dyba; Dag I. K. Sjøberg|Simula Research Laboratory; SINTEF Information and Communication Technology|Empirical software engineering; pair programming; extreme programming; design principles; control styles; object-oriented programming; software maintainability; quasi-experiment
54|Effective Software Merging in the Presence of Object-Oriented Refactorings|2008|TSE|Danny Dig; Kashif Manzoor; Ralph Johnson; Tien N. Nguyen|The Stata Center; Techlogix; University of Illinois at Urbana-Champaign; Iowa State University|Refactoring, merging; Software Configuration Management; version control systems
55|A Controlled Experiment for Program Comprehension through Trace Visualization|2011|TSE|Bas Cornelissen; Andy Zaidman; Arie van Deursen|Software Improvement Group;Delft University of Technology|Program comprehension; dynamic analysis; controlled experiment
56|A Controlled Experiment for Evaluating the Impact of Coupling on the Maintainability of Service-Oriented Software|2011|TSE|Mikhail Perepletchikov; Caspar Ryan|RMIT University|Services systems; design concepts; maintainability; product metrics; empirical studies
57|Improving Source Code Lexicon via Traceability and Information Retrieval|2011|TSE|Andrea De Lucia; Massimiliano Di Penta; Rocco Oliveto|University of Salerno; University of Sannio; University of Molise|Software traceability; source code comprehensibility; source code identifier quality; information retrieval; software development environments; empirical software engineering
58|Comparing the Defect Reduction Benefits of Code Inspection and Test-Driven Development|2012|TSE|Jerod W. Wilkerson; Jay F. Nunamaker Jr.; Rick Mercer|Pennsylvania State University; University of Arizona|Agile programming; code inspections and walk throughs; reliability; test-driven development; testing strategies; empirical study
59|Structural Complexity and Programmer Team Strategy: An Experimental Test|2012|TSE|Narayan Ramasubbu; Chris F. Kemerer; Jeff Hong|University of Pittsburgh; Singapore Management University|Object-oriented programming; complexity measures; software quality; software productivity; programming teams; maintenance process; CK metrics; software management
60|Exploiting Dynamic Information in IDEs Improves Speed and Correctness of Software Maintenance Tasks|2012|TSE|David Rothlisberger; Marcel Harry; Walter Binder; Philippe Moret; Danilo Ansaloni; Alex Villazo; Oscar Nierstrasz|Universitat Bern; University of Lugano; Universidad Privada Boliviana|Object-oriented programming; integrated environments; restructuring; reverse engineering; reengineering; complexity measures; performance measures
61|A pilot study to compare programming effort for two parallel programming models|2008|JSS|Lorin Hochstein; Victor R. Basili; Uzi Vishkin; John Gilbert|University of Nebraska; University of Maryland; University of California|MPI; XMT; Message-passing; PRAM; Empirical study; Parallel programming; Effort
62|Comprehension strategies and difficulties in maintaining object-oriented systems: An explorative study|2007|JSS|Amela Karahasanovic; Annette Kristin Levine; Richard Thomas|Simula Research Laboratory; Software Innovation; The University of Western Australia|Maintenance; Program comprehension; Experiment; Object-oriented
63|Two controlled experiments concerning the comparison of pair programming to peer review|2005|JSS|Matthias M. Muller|Universitat Karlsruhe|Pair programming; Peer reviews; Empirical software engineering; Controlled experiment
64|An empirical investigation of the impact of the object-oriented paradigm on the maintainability of real-world mission-critical software|2005|JSS|Joa Sang Lim; Seung Ryul Jeong; Stephen R. Schach|Sangmyung University; Kookmin University; Vanderbilt University|nc
65|The task-dependent nature of the maintenance of object-oriented programs|2005|JSS|Gordon L. Freeman Jr.; Stephen R. Schach|Middle Tennessee State University; Vanderbilt University|Controlled experiment; Object-orientation; Maintenance; Inheritance; Productivity
66|An empirical investigation of an object-oriented design heuristic for maintainability|2003|JSS|Ignatios Deligiannis; Martin Shepperd; Manos Roumeliotis; Ioannis Stamelos|Technological Education Institute of Thessaloniki; Bournemouth University; University of Macedonia; Aristotle University of Thessaloniki|Object-orientation; Empirical study; Design; Heuristics; Metrics
67|A controlled experiment on inheritance depth as a cost factor for code maintenan|2003|JSS|Lutz Prechelt; Barbara Unger; Michael Philippsen; Walter Tichy|Universitat Karlsruhe|Controlled experiment; Inheritance depth; Maintenance; Cost model
68|A controlled experiment investigation of an object-oriented design heuristic for maintainability|2004|JSS|Ignatios Deligiannis; Ioannis Stamelos; Lefteris Angelis; Manos Roumeliotis; Martin Shepperd|technological education institute of thessaloniki; Aristotle University of Thessaloniki; University of Macedonia; Bournemouth University|Object-oriented; Maintainability; Experiment; Design; Heuristics
69|On the impact of trace-based feature location in the performance of software maintainers|2013|JSS|Marcelo de Almeida Maia; Raquel Fialho Lafetá|Federal University of Uberlândia|Empirical assessment; Execution traces; Feature location; Software maintenance

pub_id|title|year|venue|authors|institution|keywords
1|What Situational Information Would Help Developers When Using a Graphical Code Recommender?|2016|JSS|Seonah Lee; Sungwon Kang|Korea Advanced Institute of Science and Technology|Empirical Software Engineering;Test Driven Development;Process Quality
2|Links between the personalities, styles and performance in computer programming|2015|JSS|Zahra Karimi;Ahmad Baraani-Dastjerdi;Nasser Ghasem-Aghaee;Stefan Wagner|University of Isfahan;Universität Stuttgart|Programming styles;Personality;Five-factor model
3|Bringing Test-Driven Development to web service choreographies|2015|JSS|Felipe Besson;Paulo Moura;Fabio Kon;Dejan Milojicic|University of São Paulo;Hewlett Packard Laboratories|Automated testing;Test-Driven Development;Web service choreographies
4|Tester interactivity makes a difference in search-based software testing: A controlled experiment|2016|IST|Bogdan Marculescu; Simon Poulding; Robert Feldt; Kai Petersen; Richard Torkar|Blekinge Institute of Technology; Chalmers and the University of Gothenburg|Search-based software testing; Interactive search-based software testing; Controlled experiment
5|Evaluating the productivity of a reference-based programming approach: A controlled experiment|2014|IST|Arnon Sturm; Oded Kramer|Ben-Gurion University of Negev|Search-based software testing; Interactive search-based software testing; Controlled experiment
6|Are team personality and climate related to satisfaction and software quality? Aggregating results from a twice replicated experiment|2015|IST|Silvia T. Acuna; Marta N. Gomez; Jo E. Hannay; Natalia Juristo; Dietmar Pfahl|Universidad Autonoma de Madrid; Universidad CEU San Pablo; Norwegian Defence Research Establishment; Universidad Politecnica de Madrid; University of Tartu|Personality factors; Team climate; Software quality; Satisfaction; Replication; Meta-analysis
7|Towards an Operationalization of Test-driven Development Skills: An Industrial Empirical Study|2015|IST|Davide Fucci; Burak Turhan; Natalia Juristo; Oscar Dieste; Ayse Tosun Misirli; Markku Oivo|Universidad Politecnica de Madrid; Istanbul Technical University|test-driven development; process conformance; software quality; developers' productivity
8|An External Replication on the Effects of Test-driven Development Using a Multi-site Blind Analysis Approach|2016|ESEM|Davide Fucci; Giuseppe Scanniello; Simone Romano; Martin Shepperd; Boyce Sigweni; Fernando Uyaguari; Burak Turhan; Natalia Juristo; Markku Oivo|University of Oulu; University of Basilicata; Brunel University; Universidad Politécnica de Madrid|test-driven development; external experiment replication; blind analysis
9|An Experimental Evaluation of Test Driven Development vs. Test-Last Development with Industry Professionals|2014|EASE|Hussan Munir; Krzysztof Wnuk; Kai Petersen; Misagh Moayyed|Lund University; Blekinge Institute of Technology|Test-Driven Development; TDD; Test-Last Development; TLD; Productivity; internal or external code quality
10|Empirical study on the maintainability of Web applications: Model-driven Engineering vs Code-centric|2014|ESEJ|Y. Martínez; C. Cachero; S. Meliá|Universidad Máximo Gómez Báez de Ciego de Ávila;  Universidad de Alicante|Maintainability; Satisfaction; Quasi-experiment; MDE
11|Labeling source code with information retrievalmethods: an empirical study|2014|ESEJ|Andrea De Lucia; Massimiliano Di Penta; Rocco Oliveto; Annibale Panichella; Sebastiano Panichella|University of Salerno; University of Sannio; University of Molise|Program comprehension; Software artifact labeling; Information retrieval; Empirical studies
12|A family of experiments to assess the effectivenessand efficiency of source code obfuscation techniques|2014|ESEJ|Mariano Ceccato; Massimiliano Di Penta; Paolo Falcarin; Filippo Ricca; Marco Torchiano; Paolo Tonella|Fondazione Bruno Kessler; University of Sannio; University of East London; University of Genova; Politecnico di Torino|Program comprehension; Software artifact labeling; Information retrieval; Empirical studies
13|The impact of imperfect change rules on framework APIevolution identification: an empirical study|2015|ESEJ|Wei Wu; Adrien Serveaux; Yann-Gael Gueheneuc; Giuliano Antoniol|Ecole Polytechnique de Montreal|Software maintenance; Usefulness; Framework API evolution; Change rule
14|Prompter|2016|ESEJ|Luca Ponzanelli; Gabriele Bavota; Massimiliano Di Penta; Rocco Oliveto; Michele Lanza|Universita della Svizzera italiana; Free University of Bozen-Bolzano; University of Sannio; University of Molise|Recommenders; Mining software repositories; Stack overflow; Empirical studies
15|Evaluating Advantages of Test Driven Development: a Controlled Experiment with Professionals|2006|ISESE|Gerardo Canfora; Aniello Cimitile; Felix Garcia; Mario Piattini; Corrado Aaron Visaggio|Research Centre on Software Technology (RCOST); University of Castilla-La-Mancha|Empirical Software Engineering; Test Driven Development; Process Quality
16|An Empirical Comparison Between Pair Development and Software Inspection in Thailand|2006|ISESE|Monvorath Phongpaibul; Barry Boehm|University of Southern California; Thammasat University|Software Process Model; Software Verification; Empirical Study; Software Inspection; Pair Programming; Peer Review
17|The effect of experience on the test-driven development process|2007|ESEM|Matthias M. Muller; Andreas Höfer|Systeme Infrastruktur Support GmbH, EnBW AG; Universitat Karlsruhe|Test-driven development; Process; Quasi-experiment; Experts; Novices
18|A Replicate Empirical Comparison between Pair Development and Software Development with Inspection|2007|ISESE|Monvorath Phongpaibul; Barry Boehm|University of Southern California|Empirical Software Engineering; Test Driven Development; Process Quality
19|Comparing Inspection Methods using Controlled Experiments|2008|ESEM|Andrea De Lucia; Fausto Fasano; Giuseppe Scanniello; Genoveffa Tortora|University of Salerno; University of Basilicata|Code Inspection; Controlled Experiment; Distributed Inspection; Fagan’s Method; Pair Inspection
20|Experimental evaluation of a tool for the verification and transformation of source code in event-driven systems|2009|ESEJ|Gürcan Güles ̧ir; Klaas van den Berg; Lodewijk Bergmans; Mehmet Aks it|University of Twente|Event-driven systems; Source code verification; Source code transformation; Formal experiment
21|Does Aspect-Oriented Programming Increase the Development Speed for Crosscutting Code? An Empirical Study|2009|ESEM|Stefan Hanenberg; Sebastian Kleinschmager; Manuel Josupeit-Walter|University of Duisburg-Essen|nc
22|Preserving Aspects via Automation: a Maintainability Study|2011|ESEM|Aram Hovsepyan; Riccardo Scandariato; Stefan Van Baelen; Wouter Joosen; Serge Demeyer|Katholieke Universiteit Leuven; Universiteit Antwerpen|Experimental study; domain specific modeling; model driven engineering
23|Evaluating Methods and Technologies in Software Engineering with Respect to Developers’ Skill Level|2012|EASE|Gunnar R. Bergersen; Dag I. K. Sjøberg|University of Oslo|programming skill; pretest; experimental control; debugging; performance; replication
24|Plat_Forms 2011: Finding Emergent Properties of Web Application Development Platforms|2012|ESEM|Ulrich Stärk; Lutz Prechelt; Ilija Jolevski|Freie Universität Berlin; University St. Kliment Ohridski|Experiment; Web Development; Platforms; Comparison; Emergent Properties; Languages; Empirical Software Engineering
25|Are Forward Designed or Reverse-Engineered UML Diagrams More Helpful for Code Maintenance?: A Controlled Experiment|2013|EASE|Ana M. Fernández-Sáez; Michel R.V. Chaudron; Marcela Genero; Isabel Ramos|Leiden University; Chalmers University of Technology; University of Gothenburg; University of Castilla-La-Mancha; University of Seville|Software Maintenance; UML Diagrams; Reverse Engineering; Controlled Experiment; Survey
26|A Replicated Experiment on the Effectiveness of Test-first Development|2013|ESEM|Davide Fucci; Burak Turhan|University of Oulu|nc
27|Are Reviews an Alternative to Pair Programming ?|2004|ESEM|Matthias M. Muller|Universitat Karlsruhe|nc
28|Using Students as Experiment Subjects – An Analysis on Graduate and Freshmen Student Data|2003|EASE|Per Runeson|Lund University|nc
29|Comparing Code Reading Techniques Applied to Object-oriented Software Frameworks with regard to Effectiveness and Defect Detection Rate|2004|ISESE|Zeiad Abdelnabi; Giovanni Cantone; Marcus Ciolkowski; Dieter Rombach|University of Rome “Tor Vergata”|nc
30|Effects of Pair Programming at the Development Team Level: An Experiment|2005|ESEM|Jari Vanhanen; Casper Lassenius|Helsinki University of Technology|nc
31|A Controlled Experiment Comparing the Maintainability of Programs Designed with and without Design Patterns - A Replication in a Real Programming Environment|2004|ESEJ|MAREK VOKA ́ Cˇ; WALTER TICHY; DAG I. K. SJØBERG; ERIK ARISHOLM; MAGNE ALDRIN|Simula Research Laboratory; Universitat Karlsruhe; Norwegian Computing Center|Controlled experiment; design patterns; real programming environment; qualitative results
32|Answering software evolution questions: An empirical evaluation|2012|IST|Lile Hattori; Marco D’Ambros; Michele Lanza; Mircea Lungu|University of Lugano; University of Berne|Software evolution; Empirical evaluation; Controlled experiment; Software change history; Mining software repositories
33|More testers – The effect of crowd size and time restriction in software testing|2013|IST|Mika V. Mäntylä; Juha Itkonen|Aalto University; Lund University|Software testing; Group performance Division of labor; Human factors Crowdsourcing; Methods for SQA and V&V
34|Self-assessment of performance in software inspection processes|2004|IST|Zhichao Yina; Alistair Dunsmoreb; James Miller|University of Alberta; University of Strathclyde|Inspection; Defects; Subjective estimation
35|A structured experiment of test-driven development|2003|IST|Boby Georgea; Laurie Williams|Virginia Polytechnic Institute and State University; North Carolina State University|Software engineering; Test driven development; Extreme programming; Agile methodologies
36|Assessing defect detection performance of interacting teams in object-oriented design inspection|2004|IST|Giedre Sabaliauskaitea; Shinji Kusumoto; Katsuro Inoue|Osaka University; Kaunas University of Technology|Software inspection; Inspection meeting; False positives
37|Experimental comparison of the comprehensibility of a Z specification and its implementation in Java|2004|IST|C.F. Snooka; R. Harrison|University of Southampton; University of Reading|Empirical assessment; Formal Specification; Comprehension
38|Exploring the underlying aspects of pair programming: The impact of personality|2008|IST|Kyungsub S. Choi; Fadi P. Deek; Il Im|Manhattan College; New Jersey Institute of Technology; Yonsei University; University Heights|Pair programming; Team programming; Collaborative programming; Myers–Briggs Type Indicator; Personality
39|The effect of task order on the maintainability of object-oriented software|2009|IST|Alf Inge Wang; Erik Arisholm|Norwegian University of Science and Technology; Simula Research Laboratory; University of Oslo|Object-oriented design; Object-oriented programming; Maintainability; Maintenance planning; Software maintenance; Schedule and organizational issues
40|Empirical investigation towards the effectiveness of Test First programming|2009|IST|Liang Huang; Mike Holcombe|University of Sheffield|Agile methods; Empirical software engineering; Software testing; Testing strategies; Software engineering process; Programming paradigms
41|The impacts of function extraction technology on program comprehension: A controlled experiment|2008|IST|Rosann Webb Collins; Alan R. Hevner; Gwendolyn H. Walton; Richard C. Linger|University of South Florida; Florida Southern College; Carnegie-Mellon University|Program comprehension; Behavior understanding; Knowledge workers; Software development; Function extraction
42|The impact of Test-First programming on branch coverage and mutation score indicator of unit tests: An experiment|2010|IST|Lech Madeyski|Wroclaw University of Technology|Empirical study; Test-First programming; Test-driven development; Unit tests
43|A controlled experiment in assessing and estimating software maintenance tasks|2011|IST|Vu Nguyen; Barry Boehm; Phongphan Danphitsanuphan|University of Southern California; King Mongkut’s University of Technology North Bangkok|Software maintenance; Software estimation; Maintenance experiment; COCOMO; Maintenance size
44|Impact of test-driven development on productivity, code and tests: A controlled experiment|2011|IST|Matjaz Pancur; Mojca Ciglaric|University of Ljubljana|Empirical software engineering; Controlled experiment;Test-driven development; Iterative test-last development
45|Human and program factors affecting the maintenance of programs with deployed design patterns|2012|IST|T.H. Ng; Yuen Tak Yu; S.C. Cheung; W.K. Chan|Hong Kong University of Science and Technology; City University of Hong Kong|Design patterns; Empirical study; Human factors; Pattern-deployed software; Program factors; Software maintenance
46|Design of an empirical study for comparing the usability of concurrent programming languages|2013|IST|Sebastian Nanz; Faraz Torshizi; Michela Pedroni; Bertrand Meyer|ETH Zurich; University of Toronto|Empirical study; Concurrency; Programming languages; Usability
47|A preliminary study on the impact of a pair design phase on pair programming and solo programming|2013|IST|Matthias M. Muler|Universitat Karlsruhe|Pair programming; Preliminary study; Post-development test-cases
48|Predicting Maintenance Performance Using Object-Oriented Design Complexity Metrics|2003|TSE|Rajendra K. Bandi; Vijay K. Vaishnavi; Daniel E. Turk|Indian Institute of Management; Georgia State University; Colorado State University|Object-oriented metrics; software maintenance; metrics validation; predicting software maintenance time
49|Computer-Mediated Group Support, Anonymity, and the Software Inspection Process: An Empirical Investigation|2003|TSE|Padmal Vitharana; K. Ramamurthy|Syracuse University; University of Wisconsin|Anonymity; controlled experiment design; group support systems; seeded errors; software inspection; software quality assurance
50|Evaluating the Effect of a Delegated versus Centralized Control Style on the Maintainability of Object-Oriented Software|2004|TSE|Erik Arisholm; Dag I. K. Sjøberg|Simula Research Laboratory|Design principles; responsibility delegation; control styles; object-oriented design; object-oriented programming; software maintainability; controlled experiment
51|On the Effectiveness of the Test-First Approach to Programming|2005|TSE|Hakan Erdogmus; Maurizio Morisio; Marco Torchiano|National Research Council Canada; Politecnico di Torino|General programming techniques; coding tools and techniques; testing and debugging; testing strategies; productivity; Software Quality/SQA; software engineering process; programming paradigms
52|The Structural Complexity of Software: An Experimental Test|2005|TSE|David P. Darcy; Chris F. Kemerer; Sandra A. Slaughter; James E. Tomayko|University of Maryland; University of Pittsburgh; Carnegie-Mellon University|Software complexity; software structure; Wood’s model of task complexity; coupling; cohesion; experiment; software maintenance; software metrics; cognition; procedural programming; object-oriented programming
53|Evaluating Pair Programming with Respect to System Complexity and Programmer Expertise|2007|TSE|Erik Arisholm; Hans Gallis; Tore Dyba; Dag I. K. Sjøberg|Simula Research Laboratory; SINTEF Information and Communication Technology|Empirical software engineering; pair programming; extreme programming; design principles; control styles; object-oriented programming; software maintainability; quasi-experiment
54|Effective Software Merging in the Presence of Object-Oriented Refactorings|2008|TSE|Danny Dig; Kashif Manzoor; Ralph Johnson; Tien N. Nguyen|The Stata Center; Techlogix; University of Illinois at Urbana-Champaign; Iowa State University|Refactoring, merging; Software Configuration Management; version control systems
55|A Controlled Experiment for Program Comprehension through Trace Visualization|2011|TSE|Bas Cornelissen; Andy Zaidman; Arie van Deursen|Software Improvement Group;Delft University of Technology|Program comprehension; dynamic analysis; controlled experiment
56|A Controlled Experiment for Evaluating the Impact of Coupling on the Maintainability of Service-Oriented Software|2011|TSE|Mikhail Perepletchikov; Caspar Ryan|RMIT University|Services systems; design concepts; maintainability; product metrics; empirical studies
57|Improving Source Code Lexicon via Traceability and Information Retrieval|2011|TSE|Andrea De Lucia; Massimiliano Di Penta; Rocco Oliveto|University of Salerno; University of Sannio; University of Molise|Software traceability; source code comprehensibility; source code identifier quality; information retrieval; software development environments; empirical software engineering
58|Comparing the Defect Reduction Benefits of Code Inspection and Test-Driven Development|2012|TSE|Jerod W. Wilkerson; Jay F. Nunamaker Jr.; Rick Mercer|Pennsylvania State University; University of Arizona|Agile programming; code inspections and walk throughs; reliability; test-driven development; testing strategies; empirical study
59|Structural Complexity and Programmer Team Strategy: An Experimental Test|2012|TSE|Narayan Ramasubbu; Chris F. Kemerer; Jeff Hong|University of Pittsburgh; Singapore Management University|Object-oriented programming; complexity measures; software quality; software productivity; programming teams; maintenance process; CK metrics; software management
60|Exploiting Dynamic Information in IDEs Improves Speed and Correctness of Software Maintenance Tasks|2012|TSE|David Rothlisberger; Marcel Harry; Walter Binder; Philippe Moret; Danilo Ansaloni; Alex Villazo; Oscar Nierstrasz|Universitat Bern; University of Lugano; Universidad Privada Boliviana|Object-oriented programming; integrated environments; restructuring; reverse engineering; reengineering; complexity measures; performance measures
61|A pilot study to compare programming effort for two parallel programming models|2008|JSS|Lorin Hochstein; Victor R. Basili; Uzi Vishkin; John Gilbert|University of Nebraska; University of Maryland; University of California|MPI; XMT; Message-passing; PRAM; Empirical study; Parallel programming; Effort
62|Comprehension strategies and difficulties in maintaining object-oriented systems: An explorative study|2007|JSS|Amela Karahasanovic; Annette Kristin Levine; Richard Thomas|Simula Research Laboratory; Software Innovation; The University of Western Australia|Maintenance; Program comprehension; Experiment; Object-oriented
63|Two controlled experiments concerning the comparison of pair programming to peer review|2005|JSS|Matthias M. Muller|Universitat Karlsruhe|Pair programming; Peer reviews; Empirical software engineering; Controlled experiment
64|An empirical investigation of the impact of the object-oriented paradigm on the maintainability of real-world mission-critical software|2005|JSS|Joa Sang Lim; Seung Ryul Jeong; Stephen R. Schach|Sangmyung University; Kookmin University; Vanderbilt University|nc
65|The task-dependent nature of the maintenance of object-oriented programs|2005|JSS|Gordon L. Freeman Jr.; Stephen R. Schach|Middle Tennessee State University; Vanderbilt University|Controlled experiment; Object-orientation; Maintenance; Inheritance; Productivity
66|An empirical investigation of an object-oriented design heuristic for maintainability|2003|JSS|Ignatios Deligiannis; Martin Shepperd; Manos Roumeliotis; Ioannis Stamelos|Technological Education Institute of Thessaloniki; Bournemouth University; University of Macedonia; Aristotle University of Thessaloniki|Object-orientation; Empirical study; Design; Heuristics; Metrics
67|A controlled experiment on inheritance depth as a cost factor for code maintenan|2003|JSS|Lutz Prechelt; Barbara Unger; Michael Philippsen; Walter Tichy|Universitat Karlsruhe|Controlled experiment; Inheritance depth; Maintenance; Cost model
68|A controlled experiment investigation of an object-oriented design heuristic for maintainability|2004|JSS|Ignatios Deligiannis; Ioannis Stamelos; Lefteris Angelis; Manos Roumeliotis; Martin Shepperd|technological education institute of thessaloniki; Aristotle University of Thessaloniki; University of Macedonia; Bournemouth University|Object-oriented; Maintainability; Experiment; Design; Heuristics
69|On the impact of trace-based feature location in the performance of software maintainers|2013|JSS|Marcelo de Almeida Maia; Raquel Fialho Lafetá|Federal University of Uberlândia|Empirical assessment; Execution traces; Feature location; Software maintenance
70|Code Bubbles: Rethinking the User Interface Paradigm of Integrated Development Environments|2010|ICSE|Andrew Bragdon; Steven P. Reiss; Robert Zeleznik; Suman Karumuri; William Cheung; Joshua Kaplan; Christopher Coleman; Ferdi Adeputra; Joseph J. LaViola Jr.|Brown University; University of Central Florida| Integrated development environments; concurrent views; working set; source code; bubbles; navigation; debugging; human factors
71|Software Systems as Cities: A Controlled Experiment|2011|ICSE|Richard Wettel; Michele Lanza; Romain Robbes|University of Lugano; University of Chile| Software visualization; Empirical validation
72|Portfolio: Finding Relevant Functions and Their Usages|2011|ICSE|Collin McMillan;Mark Grechanik;Denys Poshyvanyk;Qing Xie; Chen Fu|College of William And Mary;Accenture Technology Lab|Code search; portfolio; pagerank; function call graph; ranking
73|Combining Functional and Imperative Programming for Multicore Software: An Empirical Study Evaluating Scala and Java|2012|ICSE|Victor Pankratius;Felix Schmidt; Gilda Garreton|Karlsruhe Institute of Technology; Oracle Corporation|
74|Recommending Source Code for Use in Rapid Software Prototypes|2012|ICSE|Collin McMillan;Negar Hariri; Denys Poshyvanyk; Jane Cleland-Huang; Bamshad Mobasher| College of William and Mary;DePaul University|software prototyping; domain analysis; recommender systems
75|An Empirical Study about the Effectiveness of Debugging When Random Test Cases Are Used|2012|ICSE|Mariano Ceccato; Alessandro Marchetto; Leonardo Mariani; Cu D. Nguyen; Paolo Tonella| Fondazione Bruno Kessler; University of Milano Bicocca|
76|An Empirical Study on the Developers' Perception of Software Coupling|2013|ICSE|Gabriele Bavota; Bogdan Dit; Rocco Oliveto; Massimilano Di Penta; Denys Poshyvanyk; Andrea De Lucia|University of Salerno; The College of William and Mary; University of Molise; University of Sannio|Software Coupling; Empirical Studies
77|Improving Feature Location Practice with Multi-faceted Interactive Exploration|2013|ICSE|Jinshui Wang; Xin Peng; Zhenchang Xingy; Wenyun Zhao|Fudan University; Nanyang Technological University|
78|Drag-and-Drop Refactoring: Intuitive and Efficient Program Transformation|2013|ICSE|Yun Young Lee; Nicholas Chen; Ralph E. Johnson|University of Illinois|
79|Using Psycho-Physiological Measures to Assess Task Difficulty in Software Development|2014|ICSE|Thomas Fritz†; Andrew Begelb; Sebastian C. Müller†; Serap Yigit-Elliott; Manuela Züger†|University of Zurich; Microsoft Research; Exponent|psycho-physiological; task difficulty; study
80|Understanding JavaScript Event-Based Interactions|2014|ICSE|Saba Alimadadi; Sheldon Sequeira; Ali Mesbah; Karthik Pattabiraman|University of British Columbia|Program comprehension; event-based interactions; JavaScript
81|CodeHint: Dynamic and Interactive Synthesis of Code Snippets|2014|ICSE|Joel Galenson; Philip Reames; Rastislav Bodik; Björn Hartmann; Koushik Sen|University of California|Program synthesis; IDE
82|Manual Refactoring Changes with Automated Refactoring Validation|2014|ICSE|Xi Ge; Emerson Murphy-Hill|NC State University|Refactoring; Restructuring; Tool; IDE
83|Feature Maintenance with Emergent Interfaces|2014|ICSE|Márcio Ribeiro;Paulo Borba;Christian Kästner|Federal University of Alagoas;Federal University of Pernambuco; Carnegie Mellon University|Product Lines; Interfaces; Preprocessors; Controlled Experiments
84|How Do API Documentation and Static Typing Affect API Usability?|2014|ICSE|Stefan Endrikat;Stefan Hanenberg;Romain Robbes;Andreas Stefik|University of Duisburg-Essen;University of Chile;University of Las Vegas|API Usability; Documentation; Static Type Systems
85|Cascade: A Universal Type Qualifier Inference Tool|2015|ICSE|Mohsen Vakilian; Amarin Phaosawasdi; Michael D. Ernst; Ralph E. Johnson|University of Illinois at Urbana-Champaign; University of Washington|
86|Supporting Selective Undo in a Code Editor|2015|ICSE|YoungSeok Yoon; Brad A. Myers|Carnegie Mellon University|Selective undo; backtracking
87|Are Students Representatives of Professionals in Software Engineering Experiments?|2015|ICSE|Iflaah Salman;Ayse Tosun Misirli;Natalia Juristo|University of Oulu;Istanbul Technical University;Universidad Politécnica de Madrid|experimentation; empirical study; test-driven development; code quality
88|Tempura: Temporal Dimension for IDEs|2015|ICSE|Yun Young Lee; Darko Marinov; Ralph E. Johnson|University of Illinois at Urbana-Champaign|
89|Debugging for Reactive Programming|2016|ICSE|Guido Salvaneschi; Mira Mezini|Technical University of Darmstadt|Functional-reactive Programming; Debugging
90|An Empirical Study on the Impact of C++ Lambdas and Programmer Experience|2016|ICSE|Phillip Merlin Uesbeck; Andreas Stefik;Stefan Hanenberg; Jan Pedersen; Patrick Daleiden|University of Nevada; University of Duisburg-Essen|Lambda Expressions; Human Factors; C++11
91|The Impact of Test Case Summaries on Bug Fixing Performance: An Empirical Investigation|2016|ICSE|Sebastiano Panichella; Annibale Panichella; Moritz Beller; Andy Zaidman; Harald C. Gall|University of Zurich; Delft University of Technology|Software testing; Test Case Summarization; Empirical Study
92|Do Developers Read Compiler Error Messages?|2017|ICSE|Titus Barik; Justin Smith; Kevin Lubick; Elisabeth Holmesz; Jing Fengy; Emerson Murphy-Hill; Chris Parnin|North Carolina State University;Washington and Lee University|compiler errors; eye tracking; integrated development environments; programmer comprehension; reading; visual attention
93|Supporting Software Developers with a Holistic Recommender System|2017|ICSE|Luca Ponzanelli; Simone Scalabrinoy; Gabriele Bavota; Andrea Mocci; Rocco Olivetoy; Massimiliano Di Pentaz; Michele Lanza|Università della Svizzera italiana; University of Molise; University of Sannio|Mining unstructured data; Recommender systems
94|Decoding the representation of code in the brain: An fMRI study of code review and expertise|2017|ICSE|Benjamin Floyd; Tyler Santander; Westley Weimer|University of Virginia|medical imaging; code comprehension; prose review
95|The Effect of Poor Source Code Lexicon and Readability on Developers' Cognitive Load|2018|ICSE|Sarah Fakhoury; Yuzhan Ma; Venera Arnaoudova; Olusola Adesope|Washington State University|Source code lexicon; biometrics; fNIRS; cognitive load; eyetracking; program comprehension
96|Descriptive Compound Identifier Names Improve Source Code Comprehension|2018|ICSE|Andrea Schankin; Annika Berger; Daniel V. Holt;Johannes C. Hofmeister;Till Riedel;Michael Beigl|Karlsruhe Institute of Technology;Heidelberg University;University of Passau|Program Comprehension; Identifier Names; Java Developers; Software Quality
97|Developer Reading Behavior While Summarizing Java Methods: Size and Context Matters|2019|ICSE|Nahla J. Abid; Bonita Sharif; Natalia Dragan; Hend Alrasheed; Jonathan I. Maletic|University of Nebraska-Lincoln;King Saud University; Kent State University|source code summarization; eye tracking; program comprehension; empirical study
98|CTRAS: Crowdsourced Test Report Aggregation and Summarization|2019|ICSE|Rui Hao; Yang Feng; James A. Jones; Yuying Li; Zhenyu Chen|Nanjing University; University of California|
99|Leveraging Artifact Trees to Evolve and Reuse Safety Cases|2019|ICSE|Ankit Agrawal;Seyedehzahra Khoshmanesh;Michael Vierhauser;Mona Rahimi; Jane Cleland-Huang; Robyn Lutz|University of Notre Dame; Iowa State University; Northern Illinois University|Change Impact; Safety Assurance Cases; Evolution; Traceability
100|Interactive Production Performance Feedback in the IDE|2019|ICSE|Jurgen Cito;Philipp Leitner;Martin Rinard;Harald C. Gall|MIT;Chalmers j University of Gothenburg;University of Zurich|software performance engineering; IDE; user study
101|Analyzing and Supporting Adaptation of Online Code Examples|2019|ICSE|Tianyi Zhang; Di Yang; Crista Lopes; Miryung Kimy|University of California; University of California|online code examples; code adaptation
102|Test-Driven Code Review: An Empirical Study|2019|ICSE|Davide Spadini; Fabio Palomba; Tobias Baum; Stefan Hanenberg; Magiel Bruntink; Alberto Bacchelli|Delft University of Technology; University of Zurich|
103|Refactoring Inspection Support for Manual Refactoring Edits|2018|TSE|Everton L. G. Alves; Myoungkyu Song; Tiago Massoni; Patriıcia D. L. Machado; Miryung Kim|Federal University of Campina Grande; The University of Nebraska at Omaha; University of California|Refactoring; refactoring anomalies; code inspection
104|A Comparison of Program Comprehension Strategies by Blind and Sighted Programmers|2018|TSE|Ameer Armaly; Paige Rodeghero; Collin McMillan|University of Notre Dame|Program comprehension; accessibility technology; blindness
105|The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells|2018|TSE|Fabio Palomba; Annibale Panichella; Andy Zaidman; Rocco Oliveto; Andrea De Lucia|TU Delft; University of Luxembourg; University of Molise; University of Salerno|Code smells; empirical study; mining software repositories
106|VT-Revolution: Interactive Programming Video Tutorial Authoring and Watching System|2019|TSE|Lingfeng Bao; Zhenchang Xing; Xin Xia; David Lo|Zhejiang University; Australian National University; Monash University; Singapore Management University|Program comprehension; human-computer interaction; workflow
107|The impact of Software Testing education on code reliability: An empirical assessment|2018|JSS|Otávio Augusto Lazzarini Lemos; Fábio Fagundes Silveira; Fabiano Cutigi Ferrari; Alessandro Garcia|Federal University of São Paulo; Federal University of São Carlos; Catholic University of Rio de Janeiro|Software Testing; Computer science education; Student experiments
108|A replicated experiment for evaluating the effectiveness of pairing practice in PSP education|2019|JSS|Guoping Rong; He Zhang; Bohan Liu; Qi Shan; Dong Shao|Nanjing University|Personal software process; Software engineering education; Replication
109|The Effect of Noise on Software Engineers’ Performance|2018|ESEM|Simone Romano; Giuseppe Scanniello; Davide Fucci; Natalia Juristo; Burak Turhan|University of Basilicata; University of Hamburg; Universidad Politecnica de Madrid; Brunel University London|Noise; controlled experiment; functional requirement; bug fixing
110|A Longitudinal Cohort Study on the Retainment of Test-Driven Development|2018|ESEM|Davide Fucci; Simone Romano;Maria Teresa Baldassarre; Danilo Caivano;Giuseppe Scanniello; Burak Turhan; Natalia Juristo|University of Hamburg; University of Basilicata; University of Bari; Monash University; Universidad Politecnica de Madrid|Test-driven development; longitudinal cohort study
111|Comparing the comprehensibility of requirements models: An experiment replication|2018|IST|Fábio Levy Siqueira|Escola Politécnica da Universidade de São Paulo|Tropos; Use case; Experiment; Replication; Comprehensibility
112|Live programming in practice: A controlled experiment on state machines for robotic behaviors|2019|IST|Miguel Campusano; Johan Fabry; Alexandre Bergel|University of Chile|Live programming; Controlled experiment; Robot behaviors; Live robot programming; Nested state machines
113|Using cognitive dimensions to evaluate the usability of security APIs: An empirical investigation|2019|IST|Chamila Wijayarathna; Nalin Asanka Gamagedara Arachchilage|Australian Defence Force Academy;La Trobe University|Security API usability; Usability evaluation; Developer experience; Cognitive dimensions
114|Does syntax highlighting help programming novices?|2018|ESE|Christoph Hannebauer1; Marc Hesenius1; Volker Gruhn|University of Duisburg-Essen|Syntax highlighting; Source code typography; Code colouring; IDE interface; Program comprehension
115|An empirical study on the impact of AspectJ on software evolvability|2018|ESE|Adam Przybyek|Gdansk University of Technology|Aspect-oriented programming; AOP; Maintainability;  Understandability; Separation of concerns; Controlled experiment
116|Noise in Mylyn interaction traces and its impact on developers and recommendation systems|2018|ESE|Zephyrin Soh; Foutse Khomh; Yann-Gael Gueheneuc; Giuliano Antoniol|Polytechnique Montreal|Software maintenance; Mylyn Interaction traces; Noise; Editing behaviour; Recommendation systems
117|Syntax, predicates, idioms—what really affects code complexity?|2019|ESE|Shulamyt Ajami; YonatanWoodbridge; Dror G. Feitelson|The Hebrew University|Code complexity; Program understanding; Gamification
118|Shorter identifier names take longer to comprehend|2019|ESE|Johannes C. Hofmeister; Janet Siegmund; Daniel V. Holt|University of Passau;Heidelberg University|Identifier names; Program comprehension; Professional C# developers; Psychology; Defect detection; Software quality
